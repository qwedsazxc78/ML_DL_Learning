{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.3426 - acc: 0.1180     \n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.3161 - acc: 0.1320     \n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.3044 - acc: 0.1410     \n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2958 - acc: 0.1390     \n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2900 - acc: 0.1490     \n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2803 - acc: 0.1620     \n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2711 - acc: 0.1710     \n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2655 - acc: 0.1660     \n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2568 - acc: 0.1760     \n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2487 - acc: 0.1790     \n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2399 - acc: 0.1750     \n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2329 - acc: 0.1930     \n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2249 - acc: 0.2000     \n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2157 - acc: 0.1960     \n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.2058 - acc: 0.1980     \n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1967 - acc: 0.2030     \n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1892 - acc: 0.2130     \n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1788 - acc: 0.2100     \n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1738 - acc: 0.2220     \n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1615 - acc: 0.2250     \n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1577 - acc: 0.2240     \n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1463 - acc: 0.2280     \n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1376 - acc: 0.2340     \n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1259 - acc: 0.2470     \n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1195 - acc: 0.2400     \n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.1083 - acc: 0.2610     \n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.1159 - acc: 0.253 - 0s - loss: 2.0989 - acc: 0.2600     \n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0888 - acc: 0.2720     \n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0796 - acc: 0.2750     \n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0701 - acc: 0.2840     \n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0608 - acc: 0.2830     \n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0508 - acc: 0.2820     \n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0388 - acc: 0.2940     \n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0282 - acc: 0.3110     \n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0223 - acc: 0.3070     \n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0089 - acc: 0.3250     \n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s - loss: 2.0020 - acc: 0.3290     \n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9921 - acc: 0.3340     \n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9811 - acc: 0.3350     \n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9679 - acc: 0.3310     \n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9582 - acc: 0.3510     \n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9500 - acc: 0.3480     \n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9390 - acc: 0.3480     \n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9305 - acc: 0.3610     \n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9221 - acc: 0.3510     \n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9056 - acc: 0.3600     \n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.9014 - acc: 0.3550     \n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8927 - acc: 0.3740     \n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8818 - acc: 0.3730     \n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8731 - acc: 0.3780     \n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8620 - acc: 0.4000     \n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8503 - acc: 0.3980     \n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8444 - acc: 0.3810     \n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8307 - acc: 0.3930     \n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8260 - acc: 0.3950     \n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8140 - acc: 0.4120     \n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.8052 - acc: 0.4010     \n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7967 - acc: 0.4170     \n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7876 - acc: 0.4210     \n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7801 - acc: 0.4140     \n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7700 - acc: 0.4170     \n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7620 - acc: 0.4330     \n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7515 - acc: 0.4210     \n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7478 - acc: 0.4240     \n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7336 - acc: 0.4360     \n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7227 - acc: 0.4370     \n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7192 - acc: 0.4500     \n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7091 - acc: 0.4470     \n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.7029 - acc: 0.4540     \n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6913 - acc: 0.4540     \n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6842 - acc: 0.4560     \n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6750 - acc: 0.4670     \n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6632 - acc: 0.4670     \n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6593 - acc: 0.4720     \n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6525 - acc: 0.4810     \n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6423 - acc: 0.4840     \n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6317 - acc: 0.4790     \n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6227 - acc: 0.4760     \n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6184 - acc: 0.4940     \n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.6117 - acc: 0.4850     \n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5992 - acc: 0.5000     \n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5893 - acc: 0.4960     \n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5862 - acc: 0.4860     \n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5793 - acc: 0.4990     \n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5687 - acc: 0.5080     \n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 1.5577 - acc: 0.5030     \n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5523 - acc: 0.5110     \n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5440 - acc: 0.5170     \n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5376 - acc: 0.5200     \n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5273 - acc: 0.5270     \n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5195 - acc: 0.5160     \n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5155 - acc: 0.5210     \n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.5083 - acc: 0.5340     \n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4983 - acc: 0.5270     \n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4894 - acc: 0.5320     \n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4869 - acc: 0.5340     \n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4775 - acc: 0.5460     \n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4670 - acc: 0.5360     \n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4650 - acc: 0.5400     \n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s - loss: 1.4574 - acc: 0.5470     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118f4b860>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env-py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
